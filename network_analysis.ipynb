{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    name: str\n",
    "        \n",
    "        \n",
    "users = [User(0, \"Hero\"), User(1,\"Dunn\"), User(2, \"Sue\"), User(3,\"Chi\"), User(4, \"Thor\"), User(5, \"Clive\"),\n",
    "        User(6, \"Hicks\"), User(7,\"Devin\"), User(8,\"Kate\"), User(9,\"Klein\")]\n",
    "\n",
    "friend_pairs = [(0,1),(0,2),(1,2),(1,3),(2,3),(3,4),(4,5),(5,6),(5,7),(6,8),(7,8),(8,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 2],\n",
       " 1: [0, 2, 3],\n",
       " 2: [0, 1, 3],\n",
       " 3: [1, 2, 4],\n",
       " 4: [3, 5],\n",
       " 5: [4, 6, 7],\n",
       " 6: [5, 8],\n",
       " 7: [5, 8],\n",
       " 8: [6, 7, 9],\n",
       " 9: [8]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# Type aliases for keeping track if Friendships\n",
    "Friendships = Dict[int, List[int]]\n",
    "\n",
    "friendships: Friendships = {user.id: [] for user in users}\n",
    "    \n",
    "for i, j in friend_pairs:\n",
    "    friendships[i].append(j)\n",
    "    friendships[j].append(i)\n",
    "    \n",
    "friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 3.5,\n",
       " 2: 3.5,\n",
       " 3: 18.0,\n",
       " 4: 20.0,\n",
       " 5: 20.5,\n",
       " 6: 6.0,\n",
       " 7: 6.0,\n",
       " 8: 8.5,\n",
       " 9: 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breadth first search algorithm for finding all shortest paths\n",
    "\n",
    "from collections import deque\n",
    "Path = List[int]\n",
    "\n",
    "def shortest_paths_from(from_user_id: int,\n",
    "                        friendships: Friendships) -> Dict[int, List[Path]]:\n",
    "    # A dictionary from \"user_id\" to *all* shortest paths to that user\n",
    "    shortest_paths_to: Dict[int, List[Path]] = {from_user_id: [[]]}\n",
    "\n",
    "    # A queue of (previous user, next user) that we need to check.\n",
    "    # Starts out with all pairs (from_user, friend_of_from_user)\n",
    "    frontier = deque((from_user_id, friend_id)\n",
    "                     for friend_id in friendships[from_user_id])\n",
    "\n",
    "    # Keep going until we empty the queue.\n",
    "    while frontier:\n",
    "        # Remove the pair that's next in the queue.\n",
    "        prev_user_id, user_id = frontier.popleft()\n",
    "\n",
    "        # Because of the way we're adding to the queue,\n",
    "        # necessarily we already know some shortest paths to prev_user\n",
    "        paths_to_prev_user = shortest_paths_to[prev_user_id]\n",
    "        new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n",
    "\n",
    "        # It's possible we already know a shortest path to user_id.\n",
    "        old_paths_to_user = shortest_paths_to.get(user_id, [])\n",
    "\n",
    "        # What's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_user:\n",
    "            min_path_length = len(old_paths_to_user[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "\n",
    "        # Only keep paths that aren't too long and are actually new\n",
    "        new_paths_to_user = [path\n",
    "                             for path in new_paths_to_user\n",
    "                             if len(path) <= min_path_length\n",
    "                             and path not in old_paths_to_user]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n",
    "\n",
    "        # Add never-seen neighbors to the frontier\n",
    "        frontier.extend((user_id, friend_id)\n",
    "                        for friend_id in friendships[user_id]\n",
    "                        if friend_id not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to\n",
    "\n",
    "# For each from_user, for each to_user, a list of shortest paths.\n",
    "shortest_paths = {user.id: shortest_paths_from(user.id, friendships)\n",
    "                  for user in users}\n",
    "\n",
    "betweenness_centrality = {user.id: 0.0 for user in users}\n",
    "for source in users:\n",
    "    for target_id, paths in shortest_paths[source.id].items():\n",
    "        if source.id < target_id: # don't double the count\n",
    "            num_paths = len(paths) # how many shortest paths\n",
    "            contrib = 1/num_paths  # Contribution to centrality\n",
    "            for path in paths:\n",
    "                for between_id in path:\n",
    "                    if between_id not in [source.id, target_id]:\n",
    "                        betweenness_centrality[between_id] += contrib\n",
    "                        \n",
    "betweenness_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.1,\n",
       " 1: 0.1,\n",
       " 2: 0.1,\n",
       " 3: 0.1,\n",
       " 4: 0.1,\n",
       " 5: 0.1,\n",
       " 6: 0.1,\n",
       " 7: 0.1,\n",
       " 8: 0.1,\n",
       " 9: 0.1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def farness(user_id: int) -> float:\n",
    "    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n",
    "    return sum(len([paths[0]]) for paths in shortest_paths[user_id].values())\n",
    "\n",
    "closeness_centrality = {user.id: 1/farness(user.id) for user in users}\n",
    "closeness_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrix_operations import Matrix, make_matrix, shape\n",
    "\n",
    "def matrix_times_matrix(m1: Matrix, m2: Matrix) -> Matrix:\n",
    "    nr1, nc1 = shape(m1)\n",
    "    nr2, nc2 = shape(m2)\n",
    "    \n",
    "    assert nc1 == nr2, \"must have (# o f columns in m1) == (# of rows in m2)\"\n",
    "    \n",
    "    def entry_fn(i: int, j: int) -> float:\n",
    "        \"\"\"dot product of i-th row of m1 with the j-th column of m2\"\"\"\n",
    "        return sum(m1[i][k]*m2[k][j] for k in range(nc1))\n",
    "    \n",
    "    return make_matrix(nr1,nc2, entry_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_operations import Vector, dot\n",
    "\n",
    "def matrix_times_vector(m: Matrix, v: Vector) -> Vector:\n",
    "    nr, nc = shape(m)\n",
    "    n = len(v)\n",
    "    assert nc == n, \"must have (# of columns in m) == (# of elements in v)\"\n",
    "    \n",
    "    return [dot(row, v) for row in m] # output has length nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the eigen vectors of matrices\n",
    "\n",
    "from typing import Tuple\n",
    "import random\n",
    "from vector_operations import magnitude, distance\n",
    "\n",
    "def find_eigenvector(m: Matrix, tolerance: float = 0.00001) -> Tuple[Vector, float]:\n",
    "    guess = [random.random() for _ in m]\n",
    "    \n",
    "    while True:\n",
    "        result = matrix_times_vector(m, guess) # transform the guess\n",
    "        norm = magnitude(result) # compute the norm\n",
    "        next_guess = [x/norm for x in result] # rescale\n",
    "        \n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            # convergence so return (eigenvector, eigenvalue)\n",
    "            return next_guess, norm\n",
    "        \n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entry_fn(i: int, j: int):\n",
    "    return 1 if (i,j) in friend_pairs or (j,i) in friend_pairs else 0\n",
    "\n",
    "n = len(users)\n",
    "adjacency_matrix = make_matrix(n,n, entry_fn)\n",
    "\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.385777729037341,\n",
       " 0.514786349344883,\n",
       " 0.514786349344883,\n",
       " 0.4733127192080188,\n",
       " 0.2336121381905662,\n",
       " 0.15015969319941735,\n",
       " 0.0835618884828145,\n",
       " 0.0835618884828145,\n",
       " 0.07285411551070305,\n",
       " 0.027297940194309752]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvector_centrality, _ = find_eigenvector(adjacency_matrix)\n",
    "eigenvector_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 0: 2, 2: 2, 3: 2, 4: 2, 6: 1, 5: 1, 8: 1, 7: 1, 9: 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n",
    "                (2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n",
    "                (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "endorsement_counts = Counter(target for source, target in endorsements)\n",
    "\n",
    "endorsement_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 54029.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.1,\n",
       " 1: 0.1,\n",
       " 2: 0.1,\n",
       " 3: 0.1,\n",
       " 4: 0.14250000000000002,\n",
       " 5: 0.1,\n",
       " 6: 0.1,\n",
       " 7: 0.1,\n",
       " 8: 0.1,\n",
       " 9: 0.1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def page_rank(users: List[User],\n",
    "             endorsements: List[Tuple[int, int]],\n",
    "             damping: float = 0.85,\n",
    "             num_iters: int = 100) -> Dict[int, float]:\n",
    "    # Compute how many people each person endorses\n",
    "    outgoing_counts = Counter(target for source, target in endorsements)\n",
    "    \n",
    "    # Initially distribute page-rank evenly\n",
    "    num_users = len(users)\n",
    "    pr = {user.id: 1/num_users for user in users}\n",
    "    \n",
    "    # small fraction of PageRank that each node gets each iteration\n",
    "    base_pr = (1 - damping)/num_users\n",
    "    \n",
    "    for iter in tqdm.trange(num_iters):\n",
    "        next_pr = {user.id: base_pr for user in users} # start with base_pr\n",
    "        \n",
    "        for source, target in endorsements:\n",
    "            # Add damped fraction of source pr to target\n",
    "            next_pr[target] += damping*pr[source]/outgoing_counts[source]\n",
    "            \n",
    "        pr = next_pr\n",
    "        \n",
    "    return pr\n",
    "\n",
    "pr = page_rank(users, endorsements)\n",
    "\n",
    "pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
